# PhytoOracle's PSII Pipeline

#### Outline

Welcome to PhytoOracle's PSII pipeline! This pipeline uses the data transformers to extract chlorophyll fluorescence data from image files. PhytoOracle's PII was developed to process data originating from University of Arizona's gantry system, the world's largest robotic field scanner. You can run our PSII pipeline on either HPC (High Performance Computing) systems or cloud based systems.

#### Transformers used

PSII currently uses 3 different transformers for data conversion:

|Order|Transformer|Process
|:-:|:-:|:-:|
1|[bin2tif](https://github.com/phytooracle/psii_bin_to_tif)|Converts bin files to GeoTIFFs|
2|[plotclip](https://github.com/phytooracle/rgb_flir_plot_clip_geojson)|Clips GeoTIFFs to agricultural plot boundaries|
3|[fluorescence segmentation](https://github.com/phytooracle/psii_segmentation)|Segments pixels given a validated set of thresholds|
4|[fluorescence aggregation](https://github.com/phytooracle/psii_fluorescence_aggregation)|aggregates segmentation data for each image and calculates F0, Fm, Fv, and Fv/Fm|

#### Data overview

PhytoOracle's psII pipeline requires a metadata file (`<metadata>.json`) for every compressed image file (`<image>.bin`). Each folder (one scan) contains one metadata file and 2 compressed images, one taken from a left camera and one taken from a right camera. We provide publicly-available data in the [CyVerse DataStore](https://datacommons.cyverse.org/browse/iplant/home/shared/terraref/ua-mac/raw_tars).

#### Setup Guide

- Download [CCTools](http://ccl.cse.nd.edu/software/downloadfiles.php) and extract it's contents within your HPC home path:
```
cd ~

wget http://ccl.cse.nd.edu/software/files/cctools-7.1.12-x86_64-centos7.tar.gz

tar -xvf cctools-7.1.12-x86_64-centos7.tar.gz
```       

- Clone the PhytoOracle repository within your HPC's storage space such as /xdisk:
```
git clone https://github.com/LyonsLab/PhytoOracle.git
```

- Change directory to psII:
```
cd PhytoOracle/psII/
```

#### Running on the HPC systems
##### Launch workers
- If using PBS: 
```
qsub worker_scripts/po_work_ocelote.pbs
```
- If using SLURM:
```
sbatch worker_scripts/po_work_puma.sh
```

##### Pipeline staging
- Download raw data:
```
iget -N 0 -KVPT /iplant/home/shared/terraref/ua-mac/raw_tars/season_10_yr_2020/ps2Top/ps2Top-<day>.tar
```

> **_NOTE:_** Replace <day> with any day you want to process. 

- Extract file contents and move the folder to the root directory:
```
tar -xvf ps2Top-<date>.tar
mv ./ps2Top/<date> .
```

- Run the pipeline interactively:
```
./manager_scripts/gpu_init_puma.sh

./run.sh <date>
```

- Submit the pipeline as a job (HPC only):
```
sbatch po_slurm_submit.sh <date> .
```

#### Running on the Cloud with HPC support

Although very similar to the steps above, to run PhytoOracle on the Cloud with HPC support, there are a few extra steps you have to carry out for data staging before starting the pipeline with ./entrypoint.sh.

Using your favouring editing tool do

```
/etc/nginx/sites-available/phyto_oracle.conf
paste the next snipped and save (changing the highlighted <fields>)

server {
        listen 80 default_server;
        listen [::]:80 default_server;

        # SSL configuration
        #
        # listen 443 ssl default_server;
        # listen [::]:443 ssl default_server;
        #
        # Note: You should disable gzip for SSL traffic.
        # See: https://bugs.debian.org/773332
        #
        # Read up on ssl_ciphers to ensure a secure configuration.
        # See: https://bugs.debian.org/765782
        #
        # Self signed certs generated by the ssl-cert package
        # Don't use them in a production server!
        #
        # include snippets/snakeoil.conf;

        root <PATH/TO/YOUR/PHYTOORACLE/PIPELINE>;

        index index.html index.htm index.nginx-debian.html;

        server_name _;

        location / {
                auth_basic "PhytoOracle Data";
        auth_basic_user_file /etc/apache2/.htpasswd;
                # First attempt to serve request as file, then
                # as directory, then fall back to displaying a 404.
                try_files $uri $uri/ =404;
                autoindex on;
        }
}
```

then from within your Transformer directory do ./nginx_reload.sh. Input your password if asked.

Open and edit process_one_set.sh :

delete the # on lines 37 and 38
remove ${HPC_PATH} on lines 24, 25, 28

